{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9a90761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bishn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bishn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8391517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 231637 entries, 0 to 231636\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   name            231636 non-null  object\n",
      " 1   id              231637 non-null  int64 \n",
      " 2   minutes         231637 non-null  int64 \n",
      " 3   contributor_id  231637 non-null  int64 \n",
      " 4   submitted       231637 non-null  object\n",
      " 5   tags            231637 non-null  object\n",
      " 6   nutrition       231637 non-null  object\n",
      " 7   n_steps         231637 non-null  int64 \n",
      " 8   steps           231637 non-null  object\n",
      " 9   description     226658 non-null  object\n",
      " 10  ingredients     231637 non-null  object\n",
      " 11  n_ingredients   231637 non-null  int64 \n",
      "dtypes: int64(5), object(7)\n",
      "memory usage: 21.2+ MB\n",
      "None\n",
      "                                         name      id  minutes  \\\n",
      "0  arriba   baked winter squash mexican style  137739       55   \n",
      "1            a bit different  breakfast pizza   31490       30   \n",
      "2                   all in the kitchen  chili  112140      130   \n",
      "3                          alouette  potatoes   59389       45   \n",
      "4          amish  tomato ketchup  for canning   44061      190   \n",
      "\n",
      "   contributor_id   submitted  \\\n",
      "0           47892  2005-09-16   \n",
      "1           26278  2002-06-17   \n",
      "2          196586  2005-02-25   \n",
      "3           68585  2003-04-14   \n",
      "4           41706  2002-10-25   \n",
      "\n",
      "                                                tags  \\\n",
      "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
      "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
      "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
      "\n",
      "                                    nutrition  n_steps  \\\n",
      "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
      "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
      "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
      "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
      "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
      "\n",
      "                                               steps  \\\n",
      "0  ['make a choice and proceed with recipe', 'dep...   \n",
      "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
      "2  ['brown ground beef in large pot', 'add choppe...   \n",
      "3  ['place potatoes in a large pot of lightly sal...   \n",
      "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  autumn is my favorite time of year to cook! th...   \n",
      "1  this recipe calls for the crust to be prebaked...   \n",
      "2  this modified version of 'mom's' chili was a h...   \n",
      "3  this is a super easy, great tasting, make ahea...   \n",
      "4  my dh's amish mother raised him on this recipe...   \n",
      "\n",
      "                                         ingredients  n_ingredients  \n",
      "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
      "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
      "2  ['ground beef', 'yellow onions', 'diced tomato...             13  \n",
      "3  ['spreadable cheese with garlic and herbs', 'n...             11  \n",
      "4  ['tomato juice', 'apple cider vinegar', 'sugar...              8  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "recipe_file = '../data/raw/food-com/RAW_recipes.csv'\n",
    "ratings_file = '../data/raw/food-com/interactions_train.csv'\n",
    "\n",
    "# Load them\n",
    "df_recipes = pd.read_csv(recipe_file)\n",
    "df_ratings = pd.read_csv(ratings_file)\n",
    "\n",
    "# See what you have\n",
    "print(df_recipes.info())\n",
    "print(df_recipes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96417907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82832 oven-specific recipes out of 231637\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_oven_data(steps_text):\n",
    "    temperature = None\n",
    "    duration = None\n",
    "\n",
    "    # 1. Find temperature\n",
    "    # Looks for patterns like \"400 F\", \"350째F\", \"200C\", \"oven to 375\"\n",
    "    temp_pattern = re.compile(r'(\\d{3})\\s?째?[FfCc]|\\b(at|to)\\s(\\d{3})\\b')\n",
    "    temp_match = temp_pattern.search(str(steps_text))\n",
    "\n",
    "    if temp_match:\n",
    "        # Grab the first number found (e.g., '350' from \"at 350\")\n",
    "        temperature = temp_match.group(1) or temp_match.group(3)\n",
    "\n",
    "    # 2. Find duration\n",
    "    # Looks for patterns like \"30 minutes\", \"1 hour\", \"25-30 min\"\n",
    "    duration_pattern = re.compile(r'(\\d+)\\s?(to|-)\\s?(\\d+)\\s?(minutes|min)|(\\d+)\\s?(minutes|min|hour|hr)')\n",
    "    duration_match = duration_pattern.search(str(steps_text))\n",
    "\n",
    "    if duration_match:\n",
    "        if duration_match.group(1): # It's a range like \"25-30\"\n",
    "            avg_time = (int(duration_match.group(1)) + int(duration_match.group(3))) / 2\n",
    "            duration = avg_time\n",
    "        elif duration_match.group(5): # It's a single time like \"45\"\n",
    "            duration = int(duration_match.group(5))\n",
    "            if 'hour' in duration_match.group(6):\n",
    "                duration = duration * 60 # Standardize to minutes\n",
    "\n",
    "    # Only return if we found *both* (it's an oven recipe)\n",
    "    if temperature and duration:\n",
    "        return int(temperature), int(duration)\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# --- Apply this to your DataFrame ---\n",
    "# This will create two new columns: 'Oven_Temp' and 'Oven_Duration'\n",
    "df_recipes[['Oven_Temp', 'Oven_Duration']] = df_recipes['steps'].apply(\n",
    "    lambda x: pd.Series(extract_oven_data(x))\n",
    ")\n",
    "\n",
    "# CRITICAL: Drop all recipes that are not for an oven\n",
    "df_oven_recipes = df_recipes.dropna(subset=['Oven_Temp', 'Oven_Duration']).copy()\n",
    "\n",
    "print(f\"Found {len(df_oven_recipes)} oven-specific recipes out of {len(df_recipes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1be58d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Columns in PP_recipes.csv ---\n",
      "['id', 'i', 'name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'calorie_level', 'ingredient_ids']\n",
      "\n",
      "--- PP_recipes.csv Head ---\n",
      "       id       i                                        name_tokens  \\\n",
      "0  424415      23  [40480, 37229, 2911, 1019, 249, 6878, 6878, 28...   \n",
      "1  146223   96900       [40480, 18376, 7056, 246, 1531, 2032, 40481]   \n",
      "2  312329  120056     [40480, 21044, 16954, 8294, 556, 10837, 40481]   \n",
      "3   74301  168258                       [40480, 10025, 31156, 40481]   \n",
      "4   76272  109030  [40480, 17841, 252, 782, 2373, 1641, 2373, 252...   \n",
      "\n",
      "                                   ingredient_tokens  \\\n",
      "0  [[2911, 1019, 249, 6878], [1353], [6953], [153...   \n",
      "1  [[17918], [25916], [2507, 6444], [8467, 1179],...   \n",
      "2  [[5867, 24176], [1353], [6953], [1301, 11332],...   \n",
      "3  [[1270, 1645, 28447], [21601], [27952, 29471, ...   \n",
      "4  [[1430, 11434], [1430, 17027], [1615, 23, 695,...   \n",
      "\n",
      "                                        steps_tokens  \\\n",
      "0  [40480, 40482, 21662, 481, 6878, 500, 246, 161...   \n",
      "1  [40480, 40482, 729, 2525, 10906, 485, 43, 8393...   \n",
      "2  [40480, 40482, 8240, 481, 24176, 296, 1353, 66...   \n",
      "3  [40480, 40482, 5539, 21601, 1073, 903, 2324, 4...   \n",
      "4  [40480, 40482, 14046, 1430, 11434, 488, 17027,...   \n",
      "\n",
      "                                          techniques  calorie_level  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...              1   \n",
      "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "\n",
      "                                      ingredient_ids  \n",
      "0                      [389, 7655, 6270, 1527, 3406]  \n",
      "1  [2683, 4969, 800, 5298, 840, 2499, 6632, 7022,...  \n",
      "2  [1257, 7655, 6270, 590, 5024, 1119, 4883, 6696...  \n",
      "3   [7940, 3609, 7060, 6265, 1170, 6654, 5003, 3561]  \n",
      "4                            [3484, 6324, 7594, 243]  \n",
      "\n",
      "--- Columns in RAW_recipes.csv ---\n",
      "['name', 'id', 'minutes', 'contributor_id', 'submitted', 'tags', 'nutrition', 'n_steps', 'steps', 'description', 'ingredients', 'n_ingredients']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define file paths\n",
    "pp_recipe_file = '../data/raw/food-com/PP_recipes.csv'\n",
    "raw_recipe_file = '../data/raw/food-com/RAW_recipes.csv'\n",
    "\n",
    "# Load them\n",
    "df_pp_recipes = pd.read_csv(pp_recipe_file)\n",
    "df_raw_recipes = pd.read_csv(raw_recipe_file)\n",
    "df_avg_ratings = df_ratings.groupby('recipe_id')['rating'].mean().reset_index()\n",
    "# --- 1. FIND THE 'SERVINGS' COLUMN ---\n",
    "# Let's inspect the columns in PP_recipes.csv\n",
    "print(\"--- Columns in PP_recipes.csv ---\")\n",
    "print(df_pp_recipes.columns.to_list())\n",
    "print(\"\\n--- PP_recipes.csv Head ---\")\n",
    "print(df_pp_recipes.head())\n",
    "\n",
    "# --- 2. FIND 'INGREDIENTS' AND 'TAGS' ---\n",
    "# We already know these are in RAW_recipes.csv\n",
    "print(\"\\n--- Columns in RAW_recipes.csv ---\")\n",
    "print(df_raw_recipes.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "784f9da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging all data sources...\n",
      "Created merged dataset with 56588 recipes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging all data sources...\")\n",
    "# Start with our oven recipes (which already has 'id', 'name', 'tags', 'Oven_Temp', 'Oven_Duration')\n",
    "df_merged = df_oven_recipes\n",
    "\n",
    "# Merge 1: Add ingredient_ids\n",
    "df_merged = pd.merge(df_merged, df_pp_recipes, on='id', how='inner')\n",
    "\n",
    "# Merge 2: Add average ratings\n",
    "df_merged = pd.merge(df_merged, df_avg_ratings, left_on='id', right_on='recipe_id', how='left')\n",
    "\n",
    "# Drop any rows where key context is missing\n",
    "df_final_v2 = df_merged.dropna(subset=['ingredient_ids', 'tags', 'rating']).copy()\n",
    "print(f\"Created merged dataset with {len(df_final_v2)} recipes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0feaed0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data with random environment values...\n",
      "Data augmentation complete.\n",
      "                                         name  Room_Temp  Room_Humidity\n",
      "0  arriba   baked winter squash mexican style       20.5           67.5\n",
      "1            a bit different  breakfast pizza       19.0           63.9\n",
      "2                          alouette  potatoes       25.5           50.3\n",
      "3                     beat this  banana bread       24.9           35.8\n",
      "4             better then bush s  baked beans       19.0           33.4\n",
      "Optimal dataset saved to ../data/processed/processed_oven_recipes_v2.csv\n",
      "       id                                        name    rating  Room_Temp  \\\n",
      "0  137739  arriba   baked winter squash mexican style  5.000000       20.5   \n",
      "1   31490            a bit different  breakfast pizza  3.000000       19.0   \n",
      "2   59389                          alouette  potatoes  4.000000       25.5   \n",
      "3   75452                     beat this  banana bread  4.250000       24.9   \n",
      "4   67547             better then bush s  baked beans  3.666667       19.0   \n",
      "\n",
      "   Room_Humidity                                     ingredient_ids  \\\n",
      "0           67.5          [7933, 4694, 4795, 3723, 840, 5006, 6270]   \n",
      "1           63.9               [5481, 6324, 2499, 4717, 6276, 1170]   \n",
      "2           50.3  [1170, 4918, 6426, 5185, 7099, 5006, 6009, 627...   \n",
      "3           35.8  [6906, 7367, 342, 2499, 2832, 5068, 911, 335, ...   \n",
      "4           33.4  [3384, 1248, 2045, 4807, 1833, 5010, 3217, 488...   \n",
      "\n",
      "                                                tags  Oven_Temp  Oven_Duration  \n",
      "0  ['60-minutes-or-less', 'time-to-make', 'course...      350.0           40.0  \n",
      "1  ['30-minutes-or-less', 'time-to-make', 'course...      425.0            5.0  \n",
      "2  ['60-minutes-or-less', 'time-to-make', 'course...      350.0          120.0  \n",
      "3  ['weeknight', 'time-to-make', 'course', 'main-...      350.0           50.0  \n",
      "4  ['weeknight', 'time-to-make', 'course', 'main-...      350.0          120.0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Augmenting data with random environment values...\")\n",
    "\n",
    "# Get the number of recipes we have\n",
    "num_recipes = len(df_final_v2) # This is 82,832\n",
    "\n",
    "# Create a random temperature for each recipe (e.g., between 15째C and 30째C)\n",
    "df_final_v2['Room_Temp'] = np.random.uniform(low=15.0, high=30.0, size=num_recipes).round(1)\n",
    "\n",
    "# Create a random humidity for each recipe (e.g., between 30% and 70%)\n",
    "df_final_v2['Room_Humidity'] = np.random.uniform(low=30.0, high=70.0, size=num_recipes).round(1)\n",
    "\n",
    "print(\"Data augmentation complete.\")\n",
    "print(df_final_v2[['name', 'Room_Temp', 'Room_Humidity']].head())\n",
    "\n",
    "final_features = [\n",
    "    'id', 'name', 'rating',\n",
    "    'Room_Temp', 'Room_Humidity',   # Inputs\n",
    "    'ingredient_ids', 'tags',       # Inputs\n",
    "    'Oven_Temp', 'Oven_Duration'    # Outputs\n",
    "]\n",
    "df_final_v2_clean = df_final_v2[final_features]\n",
    "# 4. Save your new, clean dataset!\n",
    "output_path = '../data/processed/processed_oven_recipes_v2.csv'\n",
    "df_final_v2_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Optimal dataset saved to {output_path}\")\n",
    "print(df_final_v2_clean.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
